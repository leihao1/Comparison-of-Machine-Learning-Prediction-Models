{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import scipy\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "# import scikitplot as skplt\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets \n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision.transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data sets\n",
    "DATA_PATH = 'dataset/'\n",
    "IMAGE_PATH = 'image/'\n",
    "files = []\n",
    "dfs = []\n",
    "dfs_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(X):\n",
    "    try:\n",
    "        plt.imshow(np.array(X))\n",
    "    except:\n",
    "        plt.imshow(np.array(X).transpose(1,2,0))\n",
    "    plt.show()\n",
    "    \n",
    "def dimension_reduction(x_train, x_test, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(x_train)\n",
    "    x_train= pca.transform(x_train)\n",
    "    x_test = pca.transform(x_test)\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CIFAR_10(training_batches=5, test_batches=1):\n",
    "    X_train=y_train=X_test=y_test = None\n",
    "    for b in range(1,training_batches+1):\n",
    "        with open(DATA_PATH+'data_batch_%s'%b,'rb') as file:\n",
    "            data = pickle.load(file,encoding='bytes')\n",
    "            X = np.array(data[b'data'])\n",
    "#             X = X.reshape(-1,3,32,32).transpose(0,2,3,1)\n",
    "            y = np.array(data[b'labels'])\n",
    "            try:\n",
    "                X_train = np.concatenate((X_train,X))\n",
    "                y_train = np.concatenate((y_train,y))\n",
    "            except:\n",
    "                print('first training batch')\n",
    "                X_train = X\n",
    "                y_train = y\n",
    "                \n",
    "    for b in range(1,test_batches+1):\n",
    "        with open(DATA_PATH+'test_batch','rb') as file:\n",
    "            data = pickle.load(file,encoding='bytes')\n",
    "            X = np.array(data[b'data'])\n",
    "#             X = X.reshape(-1,3,32,32).transpose(0,2,3,1)\n",
    "            y = np.array(data[b'labels'])\n",
    "            try:\n",
    "                X_test = np.concatenate((X_test,X))\n",
    "                y_test = np.concatenate((y_test,y))\n",
    "            except:\n",
    "                print('first test batch')\n",
    "                X_test = X\n",
    "                y_test = y\n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_DecisionTree(X_train, y_train):\n",
    "    print('Training DecisionTree ...')\n",
    "    tree = DecisionTreeClassifier(random_state=0)\n",
    "    param_distributions = {\n",
    "#         'max_depth' : scipy.stats.randint(100,200)\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(tree,param_distributions,n_iter=1,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    print('Training finished')\n",
    "    return randcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# X_train,y_train,X_test,y_test = load_CIFAR_10(1,1)\n",
    "# X_train,X_test = dimension_reduction(X_train,X_test,100)\n",
    "# %%time\n",
    "# trees = train_DecisionTree(X_train,y_train)\n",
    "# clf = trees.best_estimator_\n",
    "# clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_images(X):\n",
    "    return X.reshape(-1,3,32,32).transpose(0,2,3,1)\n",
    "\n",
    "def transform_data(x_train,x_test):\n",
    "    # tranform functions\n",
    "    transform = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "#         Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "#         CenterCrop(32),\n",
    "        ])\n",
    "    \n",
    "    x_train = convert_to_images(x_train)\n",
    "    x_test = convert_to_images(x_test)\n",
    "#     plot_image(x_train[0])\n",
    "    #transformed dateset\n",
    "    x_train = np.array([np.array(transform(x)) for x in x_train])\n",
    "    x_test = np.array([np.array(transform(x)) for x in x_test])\n",
    "#     plot_image(x_train[0])\n",
    "    return x_train,x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first training batch\n",
      "first test batch\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,X_test,y_test = load_CIFAR_10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test = transform_data(X_train,X_test)\n",
    "# X_train = X_train.reshape(-1,3,32,32)\n",
    "# X_test = X_test.reshape(-1,3,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train.astype(np.float32))\n",
    "X_test = torch.tensor(X_test.astype(np.float32))\n",
    "y_train = torch.tensor(y_train.astype(np.int64))\n",
    "y_test = torch.tensor(y_test.astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn parameters\n",
    "image_channels = X_train.shape[1]\n",
    "image_width = X_train.shape[2]\n",
    "num_filters = 32\n",
    "num_filters2 = 64\n",
    "num_filters3 = 128\n",
    "filter_size = 5\n",
    "pool_size = 2\n",
    "# final_input = (((image_width+1-filter_size)//pool_size+1-filter_size)//pool_size)**2*num_filters2#without padding\n",
    "final_input = (image_width//pool_size//pool_size//pool_size)**2*num_filters3#with padding\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(image_channels, num_filters, filter_size, padding=filter_size//2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(pool_size, pool_size),\n",
    "    \n",
    "    torch.nn.Conv2d(num_filters, num_filters2, filter_size, padding=filter_size//2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(pool_size, pool_size),\n",
    "    \n",
    "    torch.nn.Conv2d(num_filters2, num_filters3, filter_size, padding=filter_size//2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(pool_size, pool_size),\n",
    "    \n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(final_input, final_input//2),\n",
    "    torch.nn.ReLU(),\n",
    "    \n",
    "    torch.nn.Linear(final_input//2, final_input//4),\n",
    "    torch.nn.ReLU(),\n",
    "    \n",
    "    torch.nn.Linear(final_input//4, final_input//16),\n",
    "    torch.nn.ReLU(),\n",
    "\n",
    "    torch.nn.Linear(final_input//16,10),\n",
    ")\n",
    "\n",
    "# model2 = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(final_input, final_input//2),\n",
    "#     torch.nn.ReLU(),\n",
    "    \n",
    "#     torch.nn.Linear(final_input//2, final_input//4),\n",
    "#     torch.nn.ReLU(),\n",
    "    \n",
    "#     torch.nn.Linear(final_input//4, final_input//16),\n",
    "#     torch.nn.ReLU(),\n",
    "\n",
    "#     torch.nn.Linear(final_input//16,10),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_models(model,model2,X_train,X_test,y_train,y_test,final_input,batch_size,num_epoch):\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-3)\n",
    "#     optimizer2 = optim.SGD(model2.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-3)\n",
    "\n",
    "    #mini-batch training loop\n",
    "    for epoch in range(num_epoch):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            X, y = data\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "#             optimizer2.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "#             X2 = model(X).view(-1,final_input)\n",
    "#             y_pred = model2(X2)\n",
    "            y_pred = model(X)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#             optimizer2.step()\n",
    "\n",
    "            #avg batch loss\n",
    "            running_loss += loss.item()\n",
    "            batch = 500\n",
    "            if (i+1) % batch == 0:\n",
    "                print('Epoch: %d, Batch: %5d had avg loss: %.3f'%(epoch+1,i+1,running_loss/batch))\n",
    "                running_loss = 0.0\n",
    "        if (epoch+1) % 5 ==0:\n",
    "            torch.save(model.state_dict(), 'model_%s.pt'%epoch)\n",
    "    torch.save(model.state_dict(), 'model.pt')\n",
    "#     torch.save(model2.state_dict(), 'model2.pt')\n",
    "    print('Training Finished')\n",
    "#     return model,model2\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model loaded\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "batch_size=16\n",
    "num_epoch=28\n",
    "# create torch Dataset class from tensors\n",
    "train_set = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_set = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load('model.pt'))\n",
    "    print(\"Trained model loaded\")\n",
    "#     try:\n",
    "#         model2.load_state_dict(torch.load('model2.pt'))\n",
    "#     except:\n",
    "#         pass\n",
    "except:\n",
    "    print('Model not found, start straining...')\n",
    "#     model,model2 = train_models(model,model2,X_train,X_test,y_train,y_test,final_input,20,2)    \n",
    "    model = train_models(model,None,X_train,X_test,y_train,y_test,final_input,batch_size,num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 78.68 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        X, y = data\n",
    "#         y_proba = model2(model(X).view(-1,final_input))\n",
    "        y_proba = model(X)\n",
    "        _, y_pred = torch.max(y_proba.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (y_pred == y).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 83 %\n",
      "Accuracy of   car : 89 %\n",
      "Accuracy of  bird : 66 %\n",
      "Accuracy of   cat : 63 %\n",
      "Accuracy of  deer : 71 %\n",
      "Accuracy of   dog : 70 %\n",
      "Accuracy of  frog : 83 %\n",
      "Accuracy of horse : 81 %\n",
      "Accuracy of  ship : 87 %\n",
      "Accuracy of truck : 88 %\n"
     ]
    }
   ],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        X, y = data\n",
    "#         y_proba = model2(model(X).view(-1,final_input))\n",
    "        y_proba = model(X)\n",
    "        _, y_pred = torch.max(y_proba, 1)\n",
    "        c = (y_pred == y).squeeze()\n",
    "        for i in range(4):\n",
    "            label = y[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.zeros((1,3,32,32)).astype(np.float32)\n",
    "gray = zeros+0.5\n",
    "X = torch.tensor(gray, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(X[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loss = nn.CrossEntropyLoss()\n",
    "# input = torch.randn(1, 5, requires_grad=True)\n",
    "# target = torch.empty(1, dtype=torch.long).random_(5)\n",
    "# print(target.data)\n",
    "# for i in range(10):\n",
    "#     output = loss(input, target)\n",
    "#     output.backward()\n",
    "#     input.data -= 0.2*input.grad.data \n",
    "#     print(input.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = torch.empty(1, dtype=torch.long).random_(5)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # for i in range(10):\n",
    "# y_proba = model(X)\n",
    "# _, y_pred = torch.max(y_proba, 1)\n",
    "\n",
    "# #     loss = criterion(y_pred, target)\n",
    "# #     loss.backward()\n",
    "# y_proba.backward()\n",
    "\n",
    "# X.data += 0.2*X.grad.data    \n",
    "\n",
    "# X.grad.data.zero_()\n",
    "\n",
    "# plot_image(X[0].detach().numpy())    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.200\n",
      "-2.880\n",
      "-5.232\n",
      "-8.525\n",
      "-13.135\n",
      "-19.589\n",
      "-28.624\n",
      "-41.274\n",
      "-58.983\n",
      "-83.776\n",
      "-118.487\n",
      "-167.082\n",
      "-235.114\n",
      "-330.360\n",
      "-463.704\n",
      "-650.386\n",
      "-911.741\n",
      "-1277.637\n",
      "-1789.892\n",
      "-2507.048\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return -(x - 3)**2\n",
    "\n",
    "x = torch.tensor(0.0, requires_grad=True)\n",
    "for i in range(20):\n",
    "    # Evaluate our function transforming x into some quantity y that we want to maximize\n",
    "    y = f(x)\n",
    "\n",
    "    # Backpropagate a gradient of y with respect to x; this fills the x.grad variable\n",
    "    y.backward()\n",
    "\n",
    "    # Move x a small step in a direction that would increase y \n",
    "    x.data -= 0.2*x.grad.data\n",
    "\n",
    "    # Reset the gradient for the next iteration, since backward() always adds to the current grad value. \n",
    "    x.grad.data.zero_()\n",
    "\n",
    "    print(\"%.3f\" % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
