{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import scipy\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import scikitplot as skplt\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets \n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot tools\n",
    "def plot_roc_curve(X_test, y_test, all_clfs, clf_names):\n",
    "    roc_scores = dict()\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1.0])\n",
    "    plt.ylim([0, 1.02])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    np.random.seed(0)\n",
    "\n",
    "    for clf, clf_name in zip(all_clfs, clf_names):\n",
    "        probs = clf.predict_proba(X_test)\n",
    "        if probs.shape[1] > 2:\n",
    "            plot_multiclass_roc(y_test, probs, clf_name)\n",
    "            continue\n",
    "        preds = probs[:,1]\n",
    "        fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, preds)\n",
    "        roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "        roc_scores[clf_name] = roc_auc\n",
    "#         np.random.seed(abs(hash(clf_name))%(2**32))\n",
    "        plt.plot(fpr, tpr, 'b', label = '%s (AUC = %0.3f)' % (clf_name,roc_auc), c=np.random.rand(3,))\n",
    "        plt.legend(loc = 'lower right')\n",
    "    plt.savefig(image_path+file.split('.')[0]+'_roc')\n",
    "    plt.show()\n",
    "    return roc_scores\n",
    "\n",
    "def plot_pr_curve(X_test, y_test, all_clfs, clf_names):\n",
    "    pr_scores = dict()\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.plot([0, 1], [1, 0],'r--')\n",
    "    plt.xlim([0, 1.0])\n",
    "    plt.ylim([0, 1.02])\n",
    "    plt.ylabel('Precision')\n",
    "    plt.xlabel('Recall')\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    for clf, clf_name in zip(all_clfs, clf_names):\n",
    "        probs = clf.predict_proba(X_test)\n",
    "        if probs.shape[1]>2:\n",
    "            plot_multiclass_pr(y_test, probs, clf_name)\n",
    "            continue\n",
    "        preds = probs[:,1]\n",
    "        precision, recall, _ = sklearn.metrics.precision_recall_curve(y_test, preds)\n",
    "        pr_auc = sklearn.metrics.auc(recall, precision)\n",
    "        pr_scores[clf_name] = pr_auc\n",
    "#         np.random.seed(abs(hash(clf_name))%(2**32))\n",
    "        plt.plot(recall, precision, 'b', label = '%s (AUC = %0.3f)' % (clf_name,pr_auc), c=np.random.rand(3,))\n",
    "        plt.legend(loc = 'lower left')\n",
    "    plt.savefig(image_path+file.split('.')[0]+'_pr')\n",
    "    plt.show()\n",
    "    return pr_scores\n",
    "\n",
    "def plot_multiclass_roc(y_true, y_probas, clf_name):\n",
    "#     skplt.metrics.plot_roc(y_true, y_probas, title=clf_name+\" ROC Curve\", figsize=(10,8))\n",
    "#     skplt.metrics.plt.savefig(image_path+file.split('.')[0]+'-'+clf_name+'_multiclass_roc')\n",
    "#     skplt.metrics.plt.show()\n",
    "    pass\n",
    "    \n",
    "def plot_multiclass_pr(y_true, y_probas, clf_name):\n",
    "#     skplt.metrics.plot_precision_recall(y_true, y_probas, title=clf_name+\" PR Curve\", figsize=(10,8))\n",
    "#     skplt.metrics.plt.savefig(image_path+file.split('.')[0]+'-'+clf_name+'_multiclass_pr')\n",
    "#     skplt.metrics.plt.show()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers\n",
    "def train_KNN():\n",
    "    print('Training KNN ...')\n",
    "    knn = KNeighborsClassifier()\n",
    "#     scoring = ['roc_auc']\n",
    "    param_distributions = {\n",
    "        'n_neighbors' : scipy.stats.randint(1,20)\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(knn,param_distributions,n_iter=20,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    clf_names.append('KNN')\n",
    "    return randcv.best_estimator_\n",
    "\n",
    "def train_SVM():\n",
    "    print('Training SVM ...')\n",
    "    svm = SVC(kernel='rbf', probability=True, cache_size=3000, random_state=0)\n",
    "#     scoring = ['roc_auc']\n",
    "    param_distributions = {\n",
    "        'C' : scipy.stats.reciprocal(1.0, 100.),\n",
    "        'gamma' : scipy.stats.reciprocal(0.01, 10.),\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(svm,param_distributions,n_iter=20,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    clf_names.append('SVM')\n",
    "    return randcv.best_estimator_\n",
    "\n",
    "def train_DecisionTree():\n",
    "    print('Training DecisionTree ...')\n",
    "    tree = DecisionTreeClassifier(random_state=0)\n",
    "#     scoring = ['roc_auc']\n",
    "    param_distributions = {\n",
    "        'max_depth' : scipy.stats.randint(10,1000)\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(tree,param_distributions,n_iter=30,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    clf_names.append('Decision Tree')\n",
    "    return randcv.best_estimator_\n",
    "\n",
    "def train_RandomForest():\n",
    "    print('Training RandomForest ...')\n",
    "    forest = RandomForestClassifier(random_state=0)\n",
    "#     scoring = ['roc_auc']\n",
    "    param_distributions = {\n",
    "        'max_depth' : scipy.stats.randint(10,100),\n",
    "        'n_estimators' : scipy.stats.randint(100,1000)\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(forest,param_distributions,n_iter=10,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    clf_names.append('Random Forest')\n",
    "    return randcv.best_estimator_\n",
    "\n",
    "def train_AdaBoost():\n",
    "    print('Training AdaBoost ...')\n",
    "    boost = AdaBoostClassifier(random_state=0)\n",
    "#     scoring = ['roc_auc']\n",
    "    param_distributions = {\n",
    "        'learning_rate' : scipy.stats.uniform(0.75, 1.25),\n",
    "        'n_estimators' : scipy.stats.randint(40,70)\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(boost,param_distributions,n_iter=30,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    clf_names.append('AdaBoost')\n",
    "    return randcv.best_estimator_    \n",
    "\n",
    "def train_LogisticRegression():\n",
    "    print('Training LogisticRegression ...')\n",
    "    lr = LogisticRegression(solver='liblinear', multi_class='auto', random_state=0)\n",
    "#     scoring = ['roc_auc']\n",
    "    param_distributions = {\n",
    "        'C' : scipy.stats.reciprocal(1.0, 1000.),\n",
    "        'max_iter' : scipy.stats.randint(100,1000)\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(lr,param_distributions,n_iter=30,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    clf_names.append('Logistic regression')\n",
    "    return randcv.best_estimator_ \n",
    "\n",
    "def train_GaussianNaiveBayes():\n",
    "    print('Training GaussianNaiveBayes ...')\n",
    "    gaussian = GaussianNB()\n",
    "#     scoring = ['roc_auc']\n",
    "    param_distributions = {\n",
    "        'var_smoothing' : scipy.stats.uniform(1e-10, 1e-9),\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(gaussian,param_distributions,n_iter=30,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    clf_names.append('Gaussian Naive Bayes')\n",
    "    return randcv.best_estimator_ \n",
    "\n",
    "def train_NeuralNetwork():\n",
    "    print('Training NeuralNetwork ...')\n",
    "    nn = MLPClassifier(solver='adam', random_state=0)\n",
    "#     scoring = ['roc_auc']\n",
    "    param_distributions = {\n",
    "        'hidden_layer_sizes' : [(100,50,10)],\n",
    "        'learning_rate_init' : scipy.stats.uniform(0.001, 0.005),\n",
    "        'max_iter' : scipy.stats.randint(200,500)\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(nn,param_distributions,n_iter=10,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    clf_names.append('NeuralNetwork')\n",
    "    return randcv.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processiong tools\n",
    "def encode_labels(x_train, x_test, cols=None):\n",
    "    label_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "    if cols == None:\n",
    "        no_object = True\n",
    "        for i,t in enumerate(x_train.dtypes):\n",
    "            if t == 'object':\n",
    "                no_object = False\n",
    "                x_train.iloc[:,i] = label_encoder.fit_transform(x_train.iloc[:,i])\n",
    "                x_test.iloc[:,i] = label_encoder.transform(x_test.iloc[:,i])\n",
    "        if no_object:#no object only encode last col\n",
    "            x_train.iloc[:,-1] = label_encoder.fit_transform(x_train.iloc[:,-1])\n",
    "            x_test.iloc[:,-1] = label_encoder.transform(x_test.iloc[:,-1])    \n",
    "    else:#only encode last col\n",
    "        x_train.iloc[:] = label_encoder.fit_transform(x_train.iloc[:])\n",
    "        x_test.iloc[:] = label_encoder.transform(x_test.iloc[:])\n",
    "    return x_train, x_test\n",
    "\n",
    "#put class colunmn at end of dataframe\n",
    "def reorder_columns(dataFrame):\n",
    "    cols = dataFrame.columns.tolist()\n",
    "    cols = cols[1:] + cols[:1]\n",
    "    return dataFrame[cols]\n",
    "\n",
    "#impute ? with given strategy\n",
    "def impute_value(x_train, x_test, strategy):\n",
    "    try:\n",
    "        x_train = x_train.replace({'?' : np.nan})\n",
    "        x_test = x_test.replace({'?' : np.nan})\n",
    "    except:\n",
    "        print('no question mark found')\n",
    "    if strategy == None:\n",
    "        return x_train.dropna(), x_test.dropna()\n",
    "    else:\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy=strategy)\n",
    "        train_type_dic = dict()#keep original train data type before impute\n",
    "        for i,t in enumerate(x_train.dtypes):\n",
    "            if t != 'object':\n",
    "                train_type_dic[i] = t\n",
    "        test_type_dic = dict()#keep original test data type before impute\n",
    "        for i,t in enumerate(x_test.dtypes):\n",
    "            if t != 'object':\n",
    "                test_type_dic[i] = t        \n",
    "        x_train = pd.DataFrame(imp.fit_transform(x_train))\n",
    "        x_test = pd.DataFrame(imp.transform(x_test))\n",
    "        for key in train_type_dic:\n",
    "            x_train.iloc[:,key] = x_train.iloc[:,key].astype(train_type_dic[key])\n",
    "        for key in test_type_dic:\n",
    "            x_test.iloc[:,key] = x_test.iloc[:,key].astype(test_type_dic[key])\n",
    "        return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data sets\n",
    "data_path = 'dataset/'\n",
    "image_path = 'image/'\n",
    "\n",
    "file1 = 'messidor_features.arff'\n",
    "data1 = arff.loadarff(data_path+file1)\n",
    "df1 = pd.DataFrame(data1[0])\n",
    "# df1 = encode_labels(df1)\n",
    "\n",
    "file2 = 'default of credit card clients.xls'\n",
    "df2 = pd.read_excel(data_path+file2,index_col=0,header=1)\n",
    "df2 = df2.sample(5000,random_state=0)\n",
    "\n",
    "file3 = 'breast-cancer-wisconsin.data'\n",
    "df3 = pd.read_csv(data_path+file3,header=None, index_col=0)\n",
    "df3 = df3[df3[6]!='?'].astype('int64')\n",
    "# df3 = encode_labels(df3, [-1])\n",
    "\n",
    "file3_2 = 'wdbc.data'\n",
    "df3_2 = pd.read_csv(data_path+file3_2,header=None, index_col=0)\n",
    "df3_2 = reorder_columns(df3_2)\n",
    "# df3_2 = encode_labels(df3_2)\n",
    "\n",
    "file3_3 = 'wpbc.data'\n",
    "df3_3 = pd.read_csv(data_path+file3_3,header=None, index_col=0)\n",
    "df3_3 = reorder_columns(df3_3)\n",
    "df3_3 = df3_3[df3_3[34]!='?']\n",
    "df3_3[34] = df3_3[34].astype('int64')\n",
    "# df3_3 = encode_labels(df3_3)\n",
    "\n",
    "file4 = 'australian.dat'\n",
    "df4 = pd.read_csv(data_path+file4,header=None,sep=' ')\n",
    "df4 = reorder_columns(df4)\n",
    "\n",
    "file5 = 'german.data-numeric'\n",
    "df5 = pd.read_csv(data_path+file5,header=None,sep=' +', engine='python')\n",
    "# df5 = encode_labels(df5, [-1])\n",
    "\n",
    "#multi-class\n",
    "file6 = 'Faults.NNA'\n",
    "df6 = pd.read_csv(data_path+file6,header=None,sep='\\t', engine='python')\n",
    "cats  = df6.iloc[:,-7:].idxmax(axis=1)\n",
    "df6 = pd.concat([df6.iloc[:,:-7],cats],axis=1)\n",
    "# df6 = encode_labels(df6, [-1])\n",
    "\n",
    "file7 = 'adult.data'\n",
    "df7 = pd.read_csv(data_path+file7,header=None,sep=', ', engine='python')\n",
    "df7 = df7.sample(5000, random_state=0)\n",
    "# df7 = impute_value(df7, 'most_frequent')\n",
    "# df7 = encode_labels(df7)\n",
    "\n",
    "#multi-class\n",
    "file8 = 'yeast.data'\n",
    "df8 = pd.read_csv(data_path+file8,header=None,sep=' +', index_col=0, engine='python')\n",
    "# df8 = encode_labels(df8)\n",
    "\n",
    "#error dataset\n",
    "file9 = 'ThoraricSurgery.arff'\n",
    "data9 = arff.loadarff(data_path+file9)\n",
    "df9 = pd.DataFrame(data9[0])\n",
    "# d9 = encode_labels(df9)\n",
    "\n",
    "file10 = 'seismic-bumps.arff'\n",
    "data10, meta = arff.loadarff(data_path+file10)\n",
    "df10 = pd.DataFrame(data10)\n",
    "# df10 = encode_labels(df10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_all_clfs():\n",
    "    clf1 = train_KNN()\n",
    "    all_clfs.append(clf1)\n",
    "    clf2 = train_SVM()\n",
    "    all_clfs.append(clf2)\n",
    "    clf3 = train_DecisionTree()\n",
    "    all_clfs.append(clf3)\n",
    "    clf4 = train_RandomForest()\n",
    "    all_clfs.append(clf4)\n",
    "    clf5 = train_AdaBoost()\n",
    "    all_clfs.append(clf5)\n",
    "    clf6 = train_LogisticRegression()\n",
    "    all_clfs.append(clf6)\n",
    "    clf7 = train_GaussianNaiveBayes()\n",
    "    all_clfs.append(clf7)\n",
    "    clf8 = train_NeuralNetwork()\n",
    "    all_clfs.append(clf8)\n",
    "\n",
    "    plot_roc_curve(X_test,y_test,all_clfs,clf_names)\n",
    "    plot_pr_curve(X_test,y_test,all_clfs,clf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset : messidor_features.arff\n",
      "no question mark found\n",
      "Training KNN ...\n",
      "Training SVM ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-8c0ac7827b6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mrun_all_clfs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-44-cc7ead94fe2c>\u001b[0m in \u001b[0;36mrun_all_clfs\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mclf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_KNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mall_clfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mclf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_SVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mall_clfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mclf3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_DecisionTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-285faa949afd>\u001b[0m in \u001b[0;36mtrain_SVM\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     randcv = sklearn.model_selection.RandomizedSearchCV(svm,param_distributions,n_iter=20,cv=3,n_jobs=-1,\n\u001b[0;32m     24\u001b[0m                                                         iid=False,random_state=0)\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mrandcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mclf_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SVM'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrandcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dev\\Anaconda3\\envs\\ds\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dev\\Anaconda3\\envs\\ds\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1469\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32mD:\\dev\\Anaconda3\\envs\\ds\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dev\\Anaconda3\\envs\\ds\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dev\\Anaconda3\\envs\\ds\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    906\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    909\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dev\\Anaconda3\\envs\\ds\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    552\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    553\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dev\\Anaconda3\\envs\\ds\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dev\\Anaconda3\\envs\\ds\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "files = [file1,file2,file3,file4,file5,file6,file7,file8,file9,file10]\n",
    "dfs = [df1,df2,df3,df4,df5,df6,df7,df8,df9,df10]\n",
    "\n",
    "for file,df in zip(files,dfs):\n",
    "    all_clfs = []\n",
    "    clf_names = []\n",
    "    print(\"Dataset : %s\" % file)\n",
    "    #     df.info()\n",
    "    X = df.iloc[:,:-1]\n",
    "    y = df.iloc[:,-1]\n",
    "    assert len(y.shape) == 1, \"wrong shape of y\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "    X_train, X_test = impute_value(X_train, X_test, strategy='most_frequent')\n",
    "    X_train, X_test = encode_labels(X_train, X_test)\n",
    "#     y_train, y_test = impute_value(y_train, y_test, strategy='most_frequent')\n",
    "    y_train, y_test = encode_labels(y_train, y_test, -1)\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)    \n",
    "    run_all_clfs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
