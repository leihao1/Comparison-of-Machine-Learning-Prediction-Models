{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: \n",
    "- dimensions reduce\n",
    "- feature selection\n",
    "- maxmin scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import scipy\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import scikitplot as skplt\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets \n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "# from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processiong tools\n",
    "def normalize_data(X_train, X_test):\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)    \n",
    "    return X_train, X_test\n",
    "\n",
    "def encode_labels(x_train, x_test, cols=None):\n",
    "    label_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "    if cols == -1:#only encode last col\n",
    "        x_train.iloc[:] = label_encoder.fit_transform(x_train.iloc[:])\n",
    "        x_test.iloc[:] = label_encoder.transform(x_test.iloc[:])\n",
    "    else:\n",
    "        for i,t in enumerate(x_train.dtypes):\n",
    "            if t == 'object':\n",
    "                label_encoder.fit(df.iloc[:,i])\n",
    "                x_train.iloc[:,i] = label_encoder.transform(x_train.iloc[:,i])\n",
    "                x_test.iloc[:,i] = label_encoder.transform(x_test.iloc[:,i])           \n",
    "    return x_train, x_test\n",
    "\n",
    "#put class colunmn at end of dataframe\n",
    "def put_class_col_end(dataFrame):\n",
    "    cols = dataFrame.columns.tolist()\n",
    "    cols = cols[1:] + cols[:1]\n",
    "    return dataFrame[cols]\n",
    "\n",
    "#impute ? with given strategy\n",
    "def impute_value(x_train, x_test, strategy):\n",
    "    try:\n",
    "        x_train = x_train.replace({'?' : np.nan})\n",
    "        x_test = x_test.replace({'?' : np.nan})\n",
    "    except:\n",
    "        print('no question mark found')\n",
    "    if strategy == None:\n",
    "        return x_train.dropna(), x_test.dropna()\n",
    "    else:\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy=strategy)\n",
    "        train_type_dic = dict()#save original train data type before impute\n",
    "        for i,t in enumerate(x_train.dtypes):\n",
    "            if t != 'object':\n",
    "                train_type_dic[i] = t\n",
    "        test_type_dic = dict()#save original test data type before impute\n",
    "        for i,t in enumerate(x_test.dtypes):\n",
    "            if t != 'object':\n",
    "                test_type_dic[i] = t        \n",
    "        x_train = pd.DataFrame(imp.fit_transform(x_train))\n",
    "        x_test = pd.DataFrame(imp.transform(x_test))\n",
    "        for key in train_type_dic:\n",
    "            x_train.iloc[:,key] = x_train.iloc[:,key].astype(train_type_dic[key])\n",
    "        for key in test_type_dic:\n",
    "            x_test.iloc[:,key] = x_test.iloc[:,key].astype(test_type_dic[key])\n",
    "        return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.randint(1,20)\n",
    "scipy.stats.reciprocal(1.0, 100.),\n",
    "scipy.stats.uniform(0.75, 1.25),\n",
    "def train_SVR(X_train, y_train):\n",
    "    print('Training SVR ...')\n",
    "    svr = SVR()\n",
    "    param_distributions = {\n",
    "        'C' : scipy.stats.reciprocal(1.0, 10.),\n",
    "        'epsilon' : scipy.stats.uniform(0.1, 0.5),\n",
    "        'gamma' : scipy.stats.reciprocal(0.01, 0.1),\n",
    "    }\n",
    "    randcv = RandomizedSearchCV(svr,param_distributions,n_iter=30,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    return randcv\n",
    "\n",
    "def train_DecisionTree(X_train, y_train):\n",
    "    print('Training DecisionTree ...')\n",
    "    tree = DecisionTreeRegressor(random_state=0)\n",
    "    param_distributions = {\n",
    "        'max_depth' : scipy.stats.randint(100,1000)\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(tree,param_distributions,n_iter=30,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    return randcv\n",
    "\n",
    "def train_RandomForest(X_train, y_train):\n",
    "    print('Training RandomForest ...')\n",
    "    forest = RandomForestRegressor(random_state=0, warm_start=True)\n",
    "    param_distributions = {\n",
    "        'n_estimators' : scipy.stats.randint(100,10000)\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(forest,param_distributions,n_iter=10,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    return randcv\n",
    "\n",
    "def train_AdaBoost(X_train, y_train):\n",
    "    print('Training AdaBoost ...')\n",
    "    boost = AdaBoostRegressor(random_state=0)\n",
    "    param_distributions = {\n",
    "        'learning_rate' : scipy.stats.uniform(0.75, 1.25),\n",
    "        'n_estimators' : scipy.stats.randint(40,100)\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(boost,param_distributions,n_iter=30,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    return randcv\n",
    "\n",
    "def train_GaussianProcess(X_train, y_train):\n",
    "    print('Training GaussianNaiveBayes ...')\n",
    "    kernel = DotProduct() + WhiteKernel()\n",
    "    gaussian = GaussianProcessRegressor(kernel=kernel, normalize_y=True, random_state=0)\n",
    "    param_distributions = {\n",
    "#         'n_restarts_optimizer' : scipy.stats.randint(0,10),\n",
    "#         'alpha' : scipy.stats.uniform(1e-10, 1e-9)\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(gaussian,param_distributions,n_iter=30,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    return randcv\n",
    "\n",
    "def train_LinearRegression(X_train,y_train):\n",
    "    print('Training LinearRegression ...')\n",
    "    linear = LinearRegression(normalize=True, n_jobs=-1)\n",
    "    param_distributions = {\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(linear,param_distributions,n_iter=30,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    return randcv\n",
    "\n",
    "def train_NeuralNetwork(X_train, y_train):\n",
    "    print('Training NeuralNetwork ...')\n",
    "    nn = MLPRegressor(solver='adam', random_state=0, warm_start=True)\n",
    "    param_distributions = {\n",
    "        'hidden_layer_sizes' : [(100,50,25),(200,100,50),(200,100,50,25,1)],\n",
    "        'learning_rate_init' : scipy.stats.uniform(0.001, 0.005),\n",
    "        'max_iter' : scipy.stats.randint(200,500)\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(nn,param_distributions,n_iter=15,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    return randcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data sets\n",
    "DATA_PATH = 'dataset/'\n",
    "IMAGE_PATH = 'image/'\n",
    "files = []\n",
    "dfs = []\n",
    "\n",
    "# file1 = 'winequality-red.csv'\n",
    "# df1 = pd.read_csv(DATA_PATH+file1, delimiter=';',header=0)\n",
    "# file1_2 = 'winequality-white.csv'\n",
    "# df1_2 = pd.read_csv(DATA_PATH+file1_2, delimiter=';',header=0)\n",
    "\n",
    "file2 = 'communities.data'\n",
    "df2 = pd.read_csv(DATA_PATH+file2, delimiter=',', header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "impute_value() missing 2 required positional arguments: 'x_test' and 'strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-67885b9b857e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimpute_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: impute_value() missing 2 required positional arguments: 'x_test' and 'strategy'"
     ]
    }
   ],
   "source": [
    "impute_value(df2,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_path+'winequality-red.csv', delimiter=';',header=0)\n",
    "# df['acids'] = df['fixed acidity']+df['volatile acidity']\n",
    "\n",
    "# df['dioxides'] = df['free sulfur dioxide']+df['total sulfur dioxide']\n",
    "# df = df.drop(['fixed acidity','volatile acidity','total sulfur dioxide','free sulfur dioxide'], axis=1)\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "X_train, X_test = normalize_data(X_train, X_test)\n",
    "\n",
    "# svr = train_SVR(X_train, y_train)\n",
    "# svr = train_DecisionTree(X_train, y_train)\n",
    "# svr = train_RandomForest(X_train,y_train)\n",
    "# svr = train_AdaBoost(X_train,y_train)\n",
    "# svr = train_GaussianProcess(X_train,y_train)\n",
    "# svr = train_LinearRegression(X_train,y_train)\n",
    "# svr = train_NeuralNetwork(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svr.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr.best_estimator_.score(X_test,y_test),svr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
