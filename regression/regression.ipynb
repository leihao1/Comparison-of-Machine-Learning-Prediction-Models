{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: \n",
    "- dimensions reduce\n",
    "- feature selection\n",
    "- maxmin scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import scipy\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import scikitplot as skplt\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets \n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all(X_train, y_train, X_test, y_test, all_regrs, regr_names):\n",
    "    plt.figure(figsize=(18,8))\n",
    "    ax1 = plt.subplot(121)\n",
    "    mse_scores = plot_mse_score(X_train, y_train, X_test, y_test, all_regrs, regr_names, ax1)\n",
    "    ax2 = plt.subplot(122)\n",
    "    r2_scores = plot_r2_score(X_train, y_train, X_test, y_test, all_regrs, regr_names,ax2)\n",
    "    plt.savefig(IMAGE_PATH+file.split('.')[0]+'_mse-r2')\n",
    "    plt.show()\n",
    "\n",
    "def plot_mse_score(X_train, y_train, X_test, y_test, all_regrs, regr_names, ax):\n",
    "    mse_scores = dict()\n",
    "    training_scores = []\n",
    "    test_scores = []\n",
    "    \n",
    "    for regr, regr_name in zip(all_regrs, regr_names):\n",
    "        train_preds = regr.predict(X_train)\n",
    "        test_preds = regr.predict(X_test)\n",
    "#         if y_test.dtype == 'int64' or y_test.dtype == 'int32':\n",
    "#             train_preds = [round(p) for p in train_preds]\n",
    "#             test_preds = [round(p) for p in test_preds]\n",
    "        train_score = sklearn.metrics.mean_squared_error(y_train, train_preds)\n",
    "        test_score = sklearn.metrics.mean_squared_error(y_test, test_preds)\n",
    "        training_scores.append(train_score)\n",
    "        test_scores.append(test_score)\n",
    "        mse_scores[regr_name] = test_score\n",
    "        \n",
    "    N = len(all_regrs)\n",
    "    ind = np.arange(N)  # the x locations for the groups\n",
    "    width = 0.35       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "    p1 = plt.barh(ind-width/2, training_scores, align='center', label='Training Set', height=width)\n",
    "    p2 = plt.barh(ind+width/2, test_scores, align='center', label='Test Set', height=width)\n",
    "    for i, v in enumerate(training_scores):\n",
    "        plt.text(v+0.07,ind[i]-width/2.5,'%.3f'%v)\n",
    "        plt.text(test_scores[i]+0.07,ind[i]+width/1.5,'%.3f'%test_scores[i])\n",
    "        \n",
    "    plt.yticks(ind, regr_names) \n",
    "    plt.xlabel('MSE')\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.title('Mean Squared Error Of All Regressors')\n",
    "    plt.legend(handles=[p1,p2])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.gca().invert_xaxis()\n",
    "#     ax.yaxis.tick_right()\n",
    "    return mse_scores\n",
    "\n",
    "def plot_r2_score(X_train, y_train, X_test, y_test, all_regrs, regr_names, ax):\n",
    "    r2_scores = dict()\n",
    "    training_scores = []\n",
    "    test_scores = []\n",
    "    \n",
    "    for regr, regr_name in zip(all_regrs, regr_names):\n",
    "        train_preds = regr.predict(X_train)\n",
    "        test_preds = regr.predict(X_test)\n",
    "#         if y_test.dtype == 'int64' or y_test.dtype == 'int32':\n",
    "#             train_preds = [round(p) for p in train_preds]\n",
    "#             test_preds = [round(p) for p in test_preds]\n",
    "        train_score = sklearn.metrics.r2_score(y_train, train_preds)\n",
    "        test_score = sklearn.metrics.r2_score(y_test, test_preds)\n",
    "        training_scores.append(train_score)\n",
    "        test_scores.append(test_score)\n",
    "        r2_scores[regr_name] = test_score\n",
    "        \n",
    "    N = len(all_regrs)\n",
    "    ind = np.arange(N)  # the x locations for the groups\n",
    "    width = 0.35       # the width of the bars: can also be len(x) sequence\n",
    "\n",
    "#     p1 = plt.bar(ind, training_scores, width)\n",
    "#     p2 = plt.bar(ind+width, test_scores, width)\n",
    "#     plt.ylabel('Scores')\n",
    "#     plt.title('Scores by group and gender')\n",
    "#     plt.xticks(ind, regr_names,rotation='vertical')\n",
    "#     plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "#     plt.legend((p1[0], p2[0]), ('Training', 'Test'))\n",
    "\n",
    "    p1 = plt.barh(ind-width/2, training_scores, align='center', label='Training Set', height=width)\n",
    "    p2 = plt.barh(ind+width/2, test_scores, align='center', label='Test Set', height=width)\n",
    "    for i, v in enumerate(training_scores):\n",
    "        plt.text(v+0.01,ind[i]-width/2.5,'%.3f'%v)\n",
    "        plt.text(max(test_scores[i],0)+0.01,ind[i]+width/1.5,'%.3f'%test_scores[i])\n",
    "\n",
    "    plt.yticks(ind, regr_names)\n",
    "    plt.xlabel('R² Score')\n",
    "    plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "    plt.title('R² Scores Of All regressors')\n",
    "    plt.legend(handles=[p1,p2])\n",
    "    plt.gca().invert_yaxis()\n",
    "#     plt.gca().invert_xaxis()\n",
    "    ax.yaxis.tick_right()\n",
    "    return r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processiong tools\n",
    "def normalize_data(X_train, X_test):\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)    \n",
    "    return X_train, X_test\n",
    "\n",
    "def encode_labels(x_train, x_test, cols=None):\n",
    "    label_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "    df = pd.concat([x_train,x_test],axis=0)\n",
    "\n",
    "    if cols == -1:#only encode last col\n",
    "        if df.dtype == 'object':\n",
    "            s_df = df.iloc[:]\n",
    "            not_null_df = s_df.loc[s_df.notnull()]\n",
    "            label_encoder.fit(not_null_df)\n",
    "            try:\n",
    "                x_train.loc[:] = x_train.loc[:].astype('float')\n",
    "            except:\n",
    "                pass\n",
    "            if x_train.loc[:].dtype == 'object':\n",
    "                x_train.loc[:] = label_encoder.transform(x_train.loc[:])\n",
    "\n",
    "            try:\n",
    "                x_test.loc[:] = x_test.loc[:].astype('float')\n",
    "            except:\n",
    "                pass\n",
    "            if x_test.loc[:].dtype == 'object':\n",
    "                x_test.loc[:] = label_encoder.transform(x_test.loc[:])\n",
    "    else:\n",
    "        for i,t in enumerate(df.dtypes):\n",
    "            if t == 'object':\n",
    "                s_df = df.iloc[:,i]\n",
    "                not_null_df = s_df.loc[s_df.notnull()]\n",
    "                label_encoder.fit(not_null_df)                \n",
    "                try:\n",
    "                    x_train.iloc[:,i] = x_train.iloc[:,i].astype('float')\n",
    "                except:\n",
    "                    pass\n",
    "#                     print(\"can not convert %s th column in x_train to float\"%i) \n",
    "                if x_train.iloc[:,i].dtype == 'object':\n",
    "                    x_train.iloc[:,i] = x_train.iloc[:,i].apply(lambda x: label_encoder.transform([x])[0] if type(x) == str else x)                \n",
    "                \n",
    "                try:\n",
    "                    x_test.iloc[:,i] = x_test.iloc[:,i].astype('float')\n",
    "                except:\n",
    "                    pass\n",
    "#                     print(\"can not convert %s th column in x_test to float\"%i)\n",
    "                if x_test.iloc[:,i].dtype == 'object':\n",
    "                    x_test.iloc[:,i] = x_test.iloc[:,i].apply(lambda x: label_encoder.transform([x])[0] if type(x) == str else x)\n",
    "    return x_train, x_test\n",
    "\n",
    "#put class colunmn at end of dataframe\n",
    "def put_class_col_end(dataFrame):\n",
    "    cols = dataFrame.columns.tolist()\n",
    "    cols = cols[1:] + cols[:1]\n",
    "    return dataFrame[cols]\n",
    "\n",
    "#impute ? with given strategy\n",
    "def impute_value(x_train, x_test, strategy):\n",
    "    if strategy == None:\n",
    "        return x_train.dropna(), x_test.dropna()\n",
    "    else:\n",
    "        imp = SimpleImputer(missing_values=np.nan, strategy=strategy)\n",
    "        train_type_dic = dict()#save original train data type before impute\n",
    "        for i,t in enumerate(x_train.dtypes):\n",
    "            if t != 'object':\n",
    "                train_type_dic[i] = t\n",
    "        test_type_dic = dict()#save original test data type before impute\n",
    "        for i,t in enumerate(x_test.dtypes):\n",
    "            if t != 'object':\n",
    "                test_type_dic[i] = t        \n",
    "        x_train = pd.DataFrame(imp.fit_transform(x_train))\n",
    "        x_test = pd.DataFrame(imp.transform(x_test))\n",
    "        for key in train_type_dic:\n",
    "            x_train.iloc[:,key] = x_train.iloc[:,key].astype(train_type_dic[key])\n",
    "        for key in test_type_dic:\n",
    "            x_test.iloc[:,key] = x_test.iloc[:,key].astype(test_type_dic[key])\n",
    "        return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# scipy.stats.randint(1,20)\n",
    "# scipy.stats.reciprocal(1.0, 100.),\n",
    "# scipy.stats.uniform(0.75, 1.25),\n",
    "def train_SVR(X_train, y_train):\n",
    "    print('Training SVR ...')\n",
    "    svr = SVR()\n",
    "    param_distributions = {\n",
    "        'C' : scipy.stats.reciprocal(1.0, 10.),\n",
    "        'epsilon' : scipy.stats.uniform(0.1, 0.5),\n",
    "        'gamma' : scipy.stats.reciprocal(0.01, 0.1),\n",
    "    }\n",
    "    randcv = RandomizedSearchCV(svr,param_distributions,n_iter=30,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    return randcv\n",
    "\n",
    "def train_DecisionTree(X_train, y_train):\n",
    "    print('Training DecisionTree ...')\n",
    "    tree = DecisionTreeRegressor(random_state=0)\n",
    "    param_distributions = {\n",
    "        'max_depth' : scipy.stats.randint(100,1000)\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(tree,param_distributions,n_iter=30,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    return randcv\n",
    "\n",
    "def train_RandomForest(X_train, y_train):\n",
    "    print('Training RandomForest ...')\n",
    "    forest = RandomForestRegressor(random_state=0, warm_start=True)\n",
    "    param_distributions = {\n",
    "        'n_estimators' : scipy.stats.randint(100,1000)\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(forest,param_distributions,n_iter=10,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    return randcv\n",
    "\n",
    "def train_AdaBoost(X_train, y_train):\n",
    "    print('Training AdaBoost ...')\n",
    "    boost = AdaBoostRegressor(random_state=0)\n",
    "    param_distributions = {\n",
    "        'learning_rate' : scipy.stats.uniform(0.75, 1.25),\n",
    "        'n_estimators' : scipy.stats.randint(40,100)\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(boost,param_distributions,n_iter=30,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    return randcv\n",
    "\n",
    "def train_GaussianProcess(X_train, y_train):\n",
    "    print('Training GaussianProcess ...')\n",
    "    kernel = DotProduct()\n",
    "    gaussian = GaussianProcessRegressor(kernel=None, normalize_y=True, random_state=0)\n",
    "    param_distributions = {\n",
    "        'n_restarts_optimizer' : scipy.stats.randint(0,10),\n",
    "        'alpha' : scipy.stats.uniform(1e-9, 1e-8)\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(gaussian,param_distributions,n_iter=10,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    return randcv\n",
    "\n",
    "def train_LinearRegression(X_train,y_train):\n",
    "    print('Training LinearRegression ...')\n",
    "    linear = LinearRegression(normalize=True, n_jobs=-1)\n",
    "    param_distributions = {\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(linear,param_distributions,n_iter=30,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    return randcv\n",
    "\n",
    "def train_NeuralNetwork(X_train, y_train):\n",
    "    print('Training NeuralNetwork ...')\n",
    "    nn = MLPRegressor(solver='adam', random_state=0, warm_start=True, activation='tanh')\n",
    "    param_distributions = {\n",
    "        'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "        'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "        'hidden_layer_sizes' : [(100,50,25),(200,100,50),(200,100,50,25)],\n",
    "        'learning_rate_init' : scipy.stats.uniform(0.001, 0.005),\n",
    "        'max_iter' : scipy.stats.randint(200,500)\n",
    "    }\n",
    "    randcv = sklearn.model_selection.RandomizedSearchCV(nn,param_distributions,n_iter=15,cv=3,n_jobs=-1,\n",
    "                                                        iid=False,random_state=0)\n",
    "    randcv.fit(X_train, y_train)\n",
    "    return randcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_regrs(X_train, y_train, X_test, y_test):\n",
    "    all_regrs = []\n",
    "    regr_names = []\n",
    "\n",
    "    regr1 = train_SVR(X_train, y_train)\n",
    "    all_regrs.append(regr1.best_estimator_)\n",
    "    regr_names.append('SVR')\n",
    "\n",
    "    regr2 = train_DecisionTree(X_train, y_train)\n",
    "    all_regrs.append(regr2.best_estimator_)\n",
    "    regr_names.append('Decision Tree')\n",
    "\n",
    "    regr3 = train_RandomForest(X_train, y_train)\n",
    "    all_regrs.append(regr3.best_estimator_)\n",
    "    regr_names.append('Random Forest')\n",
    "\n",
    "    regr4 = train_AdaBoost(X_train, y_train)\n",
    "    all_regrs.append(regr4.best_estimator_)\n",
    "    regr_names.append('AdaBoost')\n",
    "\n",
    "    regr5 = train_GaussianProcess(X_train, y_train)\n",
    "    all_regrs.append(regr5.best_estimator_)\n",
    "    regr_names.append('Gaussian Process')\n",
    "\n",
    "    regr6 = train_LinearRegression(X_train, y_train)\n",
    "    all_regrs.append(regr6.best_estimator_)\n",
    "    regr_names.append('Linear Regression')\n",
    "\n",
    "    regr7 = train_NeuralNetwork(X_train, y_train)\n",
    "    all_regrs.append(regr7.best_estimator_)\n",
    "    regr_names.append('NeuralNetwork')\n",
    "\n",
    "    plot_all(X_train, y_train, X_test, y_test, all_regrs, regr_names)\n",
    "    return all_regrs, regr_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data sets\n",
    "DATA_PATH = 'dataset/'\n",
    "IMAGE_PATH = 'image/'\n",
    "files = []\n",
    "dfs = []\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "file1 = 'winequality-red.csv'\n",
    "df1 = pd.read_csv(DATA_PATH+file1, delimiter=';',header=0)\n",
    "dfs.append(df1)\n",
    "files.append(file1)\n",
    "\n",
    "file1_2 = 'winequality-white.csv'\n",
    "df1_2 = pd.read_csv(DATA_PATH+file1_2, delimiter=';',header=0)\n",
    "dfs.append(df1_2)\n",
    "files.append(file1_2)\n",
    "\n",
    "file2 = 'communities.data'\n",
    "df2 = pd.read_csv(DATA_PATH+file2, delimiter=',', header=None)\n",
    "dfs.append(df2)\n",
    "files.append(file2)\n",
    "\n",
    "file3 = 'qsar_aquatic_toxicity.csv'\n",
    "df3 = pd.read_csv(DATA_PATH+file3, delimiter=';', header=None)\n",
    "dfs.append(df3)\n",
    "files.append(file3)\n",
    "\n",
    "file4 = 'Parkinson Speech_train_data.txt'\n",
    "df4 = pd.read_csv(DATA_PATH+file4, delimiter=',', header=None)\n",
    "dfs.append(df4)\n",
    "files.append(file4)\n",
    "\n",
    "file5 = 'Facebook_dataset.csv'\n",
    "df5 = pd.read_csv(DATA_PATH+file5, delimiter=';', header=0)\n",
    "dfs.append(df5)\n",
    "files.append(file5)\n",
    "\n",
    "file6 = 'Bike Sharing_hour.csv'\n",
    "df6 = pd.read_csv(DATA_PATH+file6, delimiter=',', header=0, index_col=0)\n",
    "df6 = df6.drop(['dteday','casual','registered','yr','mnth'],axis=1)\n",
    "df6 = df6.sample(500,random_state=0)\n",
    "dfs.append(df6)\n",
    "files.append(file6)\n",
    "\n",
    "# g1 g2 g3 corelated\n",
    "file7 = 'student-por.csv'\n",
    "df7 = pd.read_csv(DATA_PATH+file7, delimiter=';', header=0)\n",
    "dfs.append(df7)\n",
    "files.append(file7)\n",
    "\n",
    "file8 = 'Concrete_Data.xls'\n",
    "df8 = pd.read_excel(DATA_PATH+file8, header=0)\n",
    "dfs.append(df8)\n",
    "files.append(file8)\n",
    "\n",
    "#241600 rows, last four y \n",
    "file9 = 'sgemm_product.csv'\n",
    "df9 = pd.read_csv(DATA_PATH+file9, delimiter=',', header=0)\n",
    "# df9 = df9.sample(5000,random_state=0)\n",
    "dfs.append(df9)\n",
    "files.append(file9)\n",
    "\n",
    "file10 = 'ACT2_competition_training.csv'\n",
    "df10 = pd.read_csv(DATA_PATH+file10, delimiter=',', header=0, index_col=0)\n",
    "df10['y'] = df10.Act\n",
    "df10 = df10.drop(['Act'],axis=1)\n",
    "dfs.append(df10)\n",
    "files.append(file10)\n",
    "\n",
    "file10_2 = 'ACT4_competition_training.csv'\n",
    "df10_2 = pd.read_csv(DATA_PATH+file10_2, delimiter=',', header=0, index_col=0)\n",
    "df10_2['y'] = df10_2.Act\n",
    "df10_2 = df10_2.drop(['Act'],axis=1)\n",
    "dfs.append(df10_2)\n",
    "files.append(file10_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df10_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D_5</th>\n",
       "      <th>D_39</th>\n",
       "      <th>D_40</th>\n",
       "      <th>D_41</th>\n",
       "      <th>D_42</th>\n",
       "      <th>D_43</th>\n",
       "      <th>D_44</th>\n",
       "      <th>D_45</th>\n",
       "      <th>D_46</th>\n",
       "      <th>D_47</th>\n",
       "      <th>...</th>\n",
       "      <th>D_10701</th>\n",
       "      <th>D_10702</th>\n",
       "      <th>D_10703</th>\n",
       "      <th>D_10706</th>\n",
       "      <th>D_10735</th>\n",
       "      <th>D_10736</th>\n",
       "      <th>D_10737</th>\n",
       "      <th>D_10742</th>\n",
       "      <th>D_10772</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOLECULE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACT4_M_5065</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACT4_M_7241</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACT4_M_11511</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACT4_M_13147</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACT4_M_15001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACT4_M_161847</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.6956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACT4_M_161848</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACT4_M_161849</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACT4_M_161850</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACT4_M_161851</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.7157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1815 rows × 4307 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               D_5  D_39  D_40  D_41  D_42  D_43  D_44  D_45  D_46  D_47  ...  \\\n",
       "MOLECULE                                                                  ...   \n",
       "ACT4_M_5065      0     0     0     0     0     0     0     0     0     0  ...   \n",
       "ACT4_M_7241      0     0     0     0     0     0     0     0     0     0  ...   \n",
       "ACT4_M_11511     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "ACT4_M_13147     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "ACT4_M_15001     0     0     0     0     0     0     0     0     0     0  ...   \n",
       "...            ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "ACT4_M_161847    0     0     0     0     0     0     0     0     0     0  ...   \n",
       "ACT4_M_161848    0     0     0     0     0     0     0     0     0     0  ...   \n",
       "ACT4_M_161849    0     0     0     0     0     0     0     0     0     0  ...   \n",
       "ACT4_M_161850    0     0     0     0     0     0     0     0     0     0  ...   \n",
       "ACT4_M_161851    0     0     0     0     0     0     0     0     0     0  ...   \n",
       "\n",
       "               D_10701  D_10702  D_10703  D_10706  D_10735  D_10736  D_10737  \\\n",
       "MOLECULE                                                                       \n",
       "ACT4_M_5065          0        0        0        0        0        0        0   \n",
       "ACT4_M_7241          0        0        0        0        0        0        0   \n",
       "ACT4_M_11511         0        0        0        0        0        0        0   \n",
       "ACT4_M_13147         0        0        0        0        0        0        0   \n",
       "ACT4_M_15001         0        0        0        0        0        0        0   \n",
       "...                ...      ...      ...      ...      ...      ...      ...   \n",
       "ACT4_M_161847        0        0        0        0        0        0        0   \n",
       "ACT4_M_161848        0        0        0        0        0        0        0   \n",
       "ACT4_M_161849        0        0        0        0        0        0        0   \n",
       "ACT4_M_161850        0        0        0        0        0        0        0   \n",
       "ACT4_M_161851        0        0        0        0        0        0        0   \n",
       "\n",
       "               D_10742  D_10772       y  \n",
       "MOLECULE                                 \n",
       "ACT4_M_5065          0        0  5.3001  \n",
       "ACT4_M_7241          0        0  4.6012  \n",
       "ACT4_M_11511         0        0  5.3001  \n",
       "ACT4_M_13147         0        0  5.3001  \n",
       "ACT4_M_15001         0        0  5.3001  \n",
       "...                ...      ...     ...  \n",
       "ACT4_M_161847        0        0  6.6956  \n",
       "ACT4_M_161848        0        0  7.0471  \n",
       "ACT4_M_161849        0        0  7.2048  \n",
       "ACT4_M_161850        0        0  6.7425  \n",
       "ACT4_M_161851        0        0  6.7157  \n",
       "\n",
       "[1815 rows x 4307 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no question mark found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = df.replace({'?' : np.nan})\n",
    "except:\n",
    "    print('no question mark found')\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "X_train, X_test = encode_labels(X_train,X_test)\n",
    "X_train, X_test = impute_value(X_train, X_test,'mean')\n",
    "X_train, X_test = normalize_data(X_train, X_test)\n",
    "# y_train, y_test = encode_labels(y_train, y_test, -1)\n",
    "# regrs, names = run_all_regrs(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot_all(X_train, y_train, X_test, y_test, regrs, names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
